{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold, RepeatedKFold, GroupKFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dprint(*args, **kwargs):\n",
    "    print(\"[{}] \".format(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M\")) + \\\n",
    "        \" \".join(map(str,args)), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = 'Id'\n",
    "target_name = 'Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('../../data/Kaggle_IADB_Competition/train.csv')\n",
    "test = pd.read_csv('../../data/Kaggle_IADB_Competition/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_test'] = 0\n",
    "test['is_test'] = 1\n",
    "df_all = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:05] Clean features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:05] Done.\n"
     ]
    }
   ],
   "source": [
    "dprint('Clean features...')\n",
    "cols = ['dependency']\n",
    "for c in tqdm(cols):\n",
    "    x = df_all[c].values\n",
    "    strs = []\n",
    "    for i, v in enumerate(x):\n",
    "        try:\n",
    "            val = float(v)\n",
    "        except:\n",
    "            strs.append(v)\n",
    "            val = np.nan\n",
    "        x[i] = val\n",
    "    strs = np.unique(strs)\n",
    "\n",
    "    for s in strs:\n",
    "        df_all[c + '_' + s] = df_all[c].apply(lambda x: 1 if x == s else 0)\n",
    "\n",
    "    df_all[c] = x\n",
    "    df_all[c] = df_all[c].astype(float)\n",
    "dprint(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dprint(\"Dummy features...\")\n",
    "# cols = ['idhogar']\n",
    "# dprint(\"len(cols) = {}\".format(len(cols)))\n",
    "# df_all = pd.get_dummies(df_all, dummy_na=True, columns=cols)\n",
    "# dprint(\"df_all.shape = {}\".format(df_all.shape))\n",
    "# dprint(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_all.loc[df_all['is_test'] == 0].drop(['is_test'], axis=1)\n",
    "test = df_all.loc[df_all['is_test'] == 1].drop(['is_test'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:06] Label Encoder...\n",
      "['edjefa', 'edjefe', 'idhogar']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:06] Done.\n"
     ]
    }
   ],
   "source": [
    "dprint('Label Encoder...')\n",
    "cols = [f_ for f_ in df_all.columns if df_all[f_].dtype == 'object' and f_ != id_name]\n",
    "print(cols)\n",
    "for c in tqdm(cols):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df_all[c].astype(str))\n",
    "    train[c] = le.transform(train[c].astype(str))\n",
    "    test[c] = le.transform(test[c].astype(str))\n",
    "del le\n",
    "gc.collect()\n",
    "dprint(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:06] Extracting features...\n"
     ]
    }
   ],
   "source": [
    "dprint(\"Extracting features...\")\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['rent_to_bedrooms'] = df['v2a1']/df['bedrooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n",
    "    df['tamhog_to_bedrooms'] = df['tamhog']/df['bedrooms']\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_bedrooms'] = df['r4t3']/df['bedrooms']\n",
    "    df['rent_to_r4t3'] = df['v2a1']/df['r4t3']\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1'])\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms']\n",
    "    df['hhsize_to_bedrooms'] = df['hhsize']/df['bedrooms']\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize']\n",
    "    df['qmobilephone_to_r4t3'] = df['qmobilephone']/df['r4t3']\n",
    "    df['qmobilephone_to_v18q1'] = df['qmobilephone']/df['v18q1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:06] Done.\n"
     ]
    }
   ],
   "source": [
    "extract_features(train)\n",
    "extract_features(test)\n",
    "dprint(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "cnt = 0\n",
    "p_buf = []\n",
    "n_splits = 5\n",
    "n_repeats = 5\n",
    "kf = RepeatedKFold(\n",
    "    n_splits=n_splits, \n",
    "    n_repeats=n_repeats, \n",
    "    random_state=0)\n",
    "err_buf = []   \n",
    "\n",
    "cols_to_drop = [\n",
    "    id_name, \n",
    "    target_name,\n",
    "]\n",
    "X = train.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "y = train[target_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-07-27 19:06] Number of classes: 4\n",
      "[2018-07-27 19:06] (9557, 158) (9557,)\n",
      "[2018-07-27 19:06] (23856, 158)\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y)\n",
    "dprint('Number of classes: {}'.format(len(classes)))\n",
    "c2i = {}\n",
    "i2c = {}\n",
    "for i, c in enumerate(classes):\n",
    "    c2i[c] = i\n",
    "    i2c[i] = c\n",
    "\n",
    "y_le = np.array([c2i[c] for c in y])\n",
    "\n",
    "X_test = test.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "id_test = test[id_name].values\n",
    "\n",
    "dprint(X.shape, y.shape)\n",
    "dprint(X_test.shape)\n",
    "\n",
    "n_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_logloss',\n",
    "    'max_depth': 32,\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.85,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'num_threads': 6,\n",
    "    'lambda_l2': 1.0,\n",
    "    'min_gain_to_split': 0,\n",
    "    'num_class': len(np.unique(y)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For encoders\n",
    "enc_cols = [\n",
    "    'idhogar', \n",
    "    'rooms', \n",
    "    'bedrooms',\n",
    "    'r4t3', \n",
    "    'hogar_adul', \n",
    "    'dependency',\n",
    "]\n",
    "feature_names_initial = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5*5\n",
      "[2018-07-27 19:07] Encoders...\n",
      "(2416, 158)\n",
      "TE\n",
      "X_train: (2416, 6), X_valid: (604, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2416, 6), X_valid_enc: (604, 6), X_train_enc: (2416, 6)\n",
      "HE0\n",
      "X_train: (2416, 158), X_valid: (604, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2416, 4), X_valid_enc: (604, 4), X_train_enc: (2416, 4)\n",
      "HE1\n",
      "X_train: (2416, 6), X_valid: (604, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2416, 4), X_valid_enc: (604, 4), X_train_enc: (2416, 4)\n",
      "(2416, 172)\n",
      "[2018-07-27 19:08] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.430827\tvalid_1's multi_logloss: 0.70214\n",
      "[200]\ttraining's multi_logloss: 0.198952\tvalid_1's multi_logloss: 0.572087\n",
      "[300]\ttraining's multi_logloss: 0.101309\tvalid_1's multi_logloss: 0.524129\n",
      "[400]\ttraining's multi_logloss: 0.054779\tvalid_1's multi_logloss: 0.506511\n",
      "[500]\ttraining's multi_logloss: 0.0316874\tvalid_1's multi_logloss: 0.504062\n",
      "Early stopping, best iteration is:\n",
      "[463]\ttraining's multi_logloss: 0.0383529\tvalid_1's multi_logloss: 0.501106\n",
      "Important features:\n",
      "0 ('idhogar', 4786)\n",
      "1 ('SQBmeaned', 3177)\n",
      "2 ('SQBage', 2000)\n",
      "3 ('col_0_he0', 1790)\n",
      "4 ('col_2_he0', 1734)\n",
      "5 ('qmobilephone_to_r4t3', 1542)\n",
      "6 ('col_3_he0', 1447)\n",
      "7 ('col_1_he0', 1435)\n",
      "8 ('tamhog_to_rooms', 1196)\n",
      "9 ('edjefa', 1117)\n",
      "10 ('SQBdependency', 1117)\n",
      "11 ('SQBedjefe', 1035)\n",
      "12 ('dependency', 1024)\n",
      "13 ('SQBescolari', 977)\n",
      "14 ('edjefe', 969)\n",
      "15 ('SQBovercrowding', 918)\n",
      "16 ('bedrooms_to_rooms', 858)\n",
      "17 ('col_0_he1', 842)\n",
      "18 ('rent_to_r4t3', 774)\n",
      "19 ('col_2_he1', 647)\n",
      "[2018-07-27 19:08] 1 F1: 0.8333508010675705\n",
      "Fold 2/5*5\n",
      "[2018-07-27 19:08] Encoders...\n",
      "(2400, 158)\n",
      "TE\n",
      "X_train: (2400, 6), X_valid: (620, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2400, 6), X_valid_enc: (620, 6), X_train_enc: (2400, 6)\n",
      "HE0\n",
      "X_train: (2400, 158), X_valid: (620, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2400, 4), X_valid_enc: (620, 4), X_train_enc: (2400, 4)\n",
      "HE1\n",
      "X_train: (2400, 6), X_valid: (620, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2400, 4), X_valid_enc: (620, 4), X_train_enc: (2400, 4)\n",
      "(2400, 172)\n",
      "[2018-07-27 19:09] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.429916\tvalid_1's multi_logloss: 0.76526\n",
      "[200]\ttraining's multi_logloss: 0.197225\tvalid_1's multi_logloss: 0.643112\n",
      "[300]\ttraining's multi_logloss: 0.098978\tvalid_1's multi_logloss: 0.596257\n",
      "[400]\ttraining's multi_logloss: 0.0528727\tvalid_1's multi_logloss: 0.586221\n",
      "Early stopping, best iteration is:\n",
      "[394]\ttraining's multi_logloss: 0.0548517\tvalid_1's multi_logloss: 0.585785\n",
      "[2018-07-27 19:09] 2 F1: 0.8215846623877169\n",
      "Fold 3/5*5\n",
      "[2018-07-27 19:09] Encoders...\n",
      "(2368, 158)\n",
      "TE\n",
      "X_train: (2368, 6), X_valid: (652, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2368, 6), X_valid_enc: (652, 6), X_train_enc: (2368, 6)\n",
      "HE0\n",
      "X_train: (2368, 158), X_valid: (652, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2368, 4), X_valid_enc: (652, 4), X_train_enc: (2368, 4)\n",
      "HE1\n",
      "X_train: (2368, 6), X_valid: (652, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2368, 4), X_valid_enc: (652, 4), X_train_enc: (2368, 4)\n",
      "(2368, 172)\n",
      "[2018-07-27 19:10] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.427984\tvalid_1's multi_logloss: 0.747234\n",
      "[200]\ttraining's multi_logloss: 0.196282\tvalid_1's multi_logloss: 0.617402\n",
      "[300]\ttraining's multi_logloss: 0.0992254\tvalid_1's multi_logloss: 0.585186\n",
      "[400]\ttraining's multi_logloss: 0.0537685\tvalid_1's multi_logloss: 0.573129\n",
      "[500]\ttraining's multi_logloss: 0.0313594\tvalid_1's multi_logloss: 0.575741\n",
      "Early stopping, best iteration is:\n",
      "[440]\ttraining's multi_logloss: 0.0430605\tvalid_1's multi_logloss: 0.571687\n",
      "[2018-07-27 19:10] 3 F1: 0.8062524504270737\n",
      "Fold 4/5*5\n",
      "[2018-07-27 19:10] Encoders...\n",
      "(2420, 158)\n",
      "TE\n",
      "X_train: (2420, 6), X_valid: (600, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2420, 6), X_valid_enc: (600, 6), X_train_enc: (2420, 6)\n",
      "HE0\n",
      "X_train: (2420, 158), X_valid: (600, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2420, 4), X_valid_enc: (600, 4), X_train_enc: (2420, 4)\n",
      "HE1\n",
      "X_train: (2420, 6), X_valid: (600, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2420, 4), X_valid_enc: (600, 4), X_train_enc: (2420, 4)\n",
      "(2420, 172)\n",
      "[2018-07-27 19:11] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.435926\tvalid_1's multi_logloss: 0.759578\n",
      "[200]\ttraining's multi_logloss: 0.205394\tvalid_1's multi_logloss: 0.650946\n",
      "[300]\ttraining's multi_logloss: 0.104443\tvalid_1's multi_logloss: 0.60719\n",
      "[400]\ttraining's multi_logloss: 0.0566615\tvalid_1's multi_logloss: 0.595359\n",
      "[500]\ttraining's multi_logloss: 0.0332282\tvalid_1's multi_logloss: 0.59988\n",
      "Early stopping, best iteration is:\n",
      "[419]\ttraining's multi_logloss: 0.0508101\tvalid_1's multi_logloss: 0.593447\n",
      "[2018-07-27 19:11] 4 F1: 0.7984056264536185\n",
      "Fold 5/5*5\n",
      "[2018-07-27 19:11] Encoders...\n",
      "(2476, 158)\n",
      "TE\n",
      "X_train: (2476, 6), X_valid: (544, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2476, 6), X_valid_enc: (544, 6), X_train_enc: (2476, 6)\n",
      "HE0\n",
      "X_train: (2476, 158), X_valid: (544, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2476, 4), X_valid_enc: (544, 4), X_train_enc: (2476, 4)\n",
      "HE1\n",
      "X_train: (2476, 6), X_valid: (544, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2476, 4), X_valid_enc: (544, 4), X_train_enc: (2476, 4)\n",
      "(2476, 172)\n",
      "[2018-07-27 19:12] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.441691\tvalid_1's multi_logloss: 0.716325\n",
      "[200]\ttraining's multi_logloss: 0.207821\tvalid_1's multi_logloss: 0.591383\n",
      "[300]\ttraining's multi_logloss: 0.107572\tvalid_1's multi_logloss: 0.540466\n",
      "[400]\ttraining's multi_logloss: 0.0587675\tvalid_1's multi_logloss: 0.519425\n",
      "[500]\ttraining's multi_logloss: 0.0345265\tvalid_1's multi_logloss: 0.515792\n",
      "[600]\ttraining's multi_logloss: 0.0216024\tvalid_1's multi_logloss: 0.519001\n",
      "Early stopping, best iteration is:\n",
      "[550]\ttraining's multi_logloss: 0.0269851\tvalid_1's multi_logloss: 0.513975\n",
      "[2018-07-27 19:12] 5 F1: 0.8157689004774465\n",
      "Fold 6/5*5\n",
      "[2018-07-27 19:12] Encoders...\n",
      "(2340, 158)\n",
      "TE\n",
      "X_train: (2340, 6), X_valid: (680, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2340, 6), X_valid_enc: (680, 6), X_train_enc: (2340, 6)\n",
      "HE0\n",
      "X_train: (2340, 158), X_valid: (680, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2340, 4), X_valid_enc: (680, 4), X_train_enc: (2340, 4)\n",
      "HE1\n",
      "X_train: (2340, 6), X_valid: (680, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2340, 4), X_valid_enc: (680, 4), X_train_enc: (2340, 4)\n",
      "(2340, 172)\n",
      "[2018-07-27 19:13] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.419497\tvalid_1's multi_logloss: 0.794588\n",
      "[200]\ttraining's multi_logloss: 0.18839\tvalid_1's multi_logloss: 0.68724\n",
      "[300]\ttraining's multi_logloss: 0.0927481\tvalid_1's multi_logloss: 0.650382\n",
      "[400]\ttraining's multi_logloss: 0.0498002\tvalid_1's multi_logloss: 0.655621\n",
      "Early stopping, best iteration is:\n",
      "[352]\ttraining's multi_logloss: 0.066357\tvalid_1's multi_logloss: 0.648884\n",
      "[2018-07-27 19:13] 6 F1: 0.7873017255201163\n",
      "Fold 7/5*5\n",
      "[2018-07-27 19:13] Encoders...\n",
      "(2456, 158)\n",
      "TE\n",
      "X_train: (2456, 6), X_valid: (564, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2456, 6), X_valid_enc: (564, 6), X_train_enc: (2456, 6)\n",
      "HE0\n",
      "X_train: (2456, 158), X_valid: (564, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2456, 4), X_valid_enc: (564, 4), X_train_enc: (2456, 4)\n",
      "HE1\n",
      "X_train: (2456, 6), X_valid: (564, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2456, 4), X_valid_enc: (564, 4), X_train_enc: (2456, 4)\n",
      "(2456, 172)\n",
      "[2018-07-27 19:13] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.42854\tvalid_1's multi_logloss: 0.70963\n",
      "[200]\ttraining's multi_logloss: 0.199602\tvalid_1's multi_logloss: 0.58835\n",
      "[300]\ttraining's multi_logloss: 0.101718\tvalid_1's multi_logloss: 0.54253\n",
      "[400]\ttraining's multi_logloss: 0.0552795\tvalid_1's multi_logloss: 0.527722\n",
      "[500]\ttraining's multi_logloss: 0.032405\tvalid_1's multi_logloss: 0.523426\n",
      "[600]\ttraining's multi_logloss: 0.0204967\tvalid_1's multi_logloss: 0.530672\n",
      "Early stopping, best iteration is:\n",
      "[512]\ttraining's multi_logloss: 0.0304961\tvalid_1's multi_logloss: 0.522522\n",
      "[2018-07-27 19:14] 7 F1: 0.8295756477821696\n",
      "Fold 8/5*5\n",
      "[2018-07-27 19:14] Encoders...\n",
      "(2440, 158)\n",
      "TE\n",
      "X_train: (2440, 6), X_valid: (580, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2440, 6), X_valid_enc: (580, 6), X_train_enc: (2440, 6)\n",
      "HE0\n",
      "X_train: (2440, 158), X_valid: (580, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2440, 4), X_valid_enc: (580, 4), X_train_enc: (2440, 4)\n",
      "HE1\n",
      "X_train: (2440, 6), X_valid: (580, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2440, 4), X_valid_enc: (580, 4), X_train_enc: (2440, 4)\n",
      "(2440, 172)\n",
      "[2018-07-27 19:14] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.440026\tvalid_1's multi_logloss: 0.701033\n",
      "[200]\ttraining's multi_logloss: 0.206655\tvalid_1's multi_logloss: 0.557109\n",
      "[300]\ttraining's multi_logloss: 0.106918\tvalid_1's multi_logloss: 0.503322\n",
      "[400]\ttraining's multi_logloss: 0.0585744\tvalid_1's multi_logloss: 0.48243\n",
      "[500]\ttraining's multi_logloss: 0.0345591\tvalid_1's multi_logloss: 0.478588\n",
      "[600]\ttraining's multi_logloss: 0.0217183\tvalid_1's multi_logloss: 0.475779\n",
      "[700]\ttraining's multi_logloss: 0.0146557\tvalid_1's multi_logloss: 0.479212\n",
      "Early stopping, best iteration is:\n",
      "[630]\ttraining's multi_logloss: 0.0191777\tvalid_1's multi_logloss: 0.474027\n",
      "[2018-07-27 19:15] 8 F1: 0.8629891660468976\n",
      "Fold 9/5*5\n",
      "[2018-07-27 19:15] Encoders...\n",
      "(2452, 158)\n",
      "TE\n",
      "X_train: (2452, 6), X_valid: (568, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2452, 6), X_valid_enc: (568, 6), X_train_enc: (2452, 6)\n",
      "HE0\n",
      "X_train: (2452, 158), X_valid: (568, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2452, 4), X_valid_enc: (568, 4), X_train_enc: (2452, 4)\n",
      "HE1\n",
      "X_train: (2452, 6), X_valid: (568, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2452, 4), X_valid_enc: (568, 4), X_train_enc: (2452, 4)\n",
      "(2452, 172)\n",
      "[2018-07-27 19:15] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.432326\tvalid_1's multi_logloss: 0.747054\n",
      "[200]\ttraining's multi_logloss: 0.201628\tvalid_1's multi_logloss: 0.619071\n",
      "[300]\ttraining's multi_logloss: 0.101453\tvalid_1's multi_logloss: 0.567231\n",
      "[400]\ttraining's multi_logloss: 0.0554909\tvalid_1's multi_logloss: 0.554669\n",
      "[500]\ttraining's multi_logloss: 0.0324653\tvalid_1's multi_logloss: 0.546464\n",
      "[600]\ttraining's multi_logloss: 0.0203489\tvalid_1's multi_logloss: 0.548695\n",
      "Early stopping, best iteration is:\n",
      "[526]\ttraining's multi_logloss: 0.0285439\tvalid_1's multi_logloss: 0.543959\n",
      "[2018-07-27 19:15] 9 F1: 0.8053211256430105\n",
      "Fold 10/5*5\n",
      "[2018-07-27 19:16] Encoders...\n",
      "(2392, 158)\n",
      "TE\n",
      "X_train: (2392, 6), X_valid: (628, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2392, 6), X_valid_enc: (628, 6), X_train_enc: (2392, 6)\n",
      "HE0\n",
      "X_train: (2392, 158), X_valid: (628, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2392, 4), X_valid_enc: (628, 4), X_train_enc: (2392, 4)\n",
      "HE1\n",
      "X_train: (2392, 6), X_valid: (628, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2392, 4), X_valid_enc: (628, 4), X_train_enc: (2392, 4)\n",
      "(2392, 172)\n",
      "[2018-07-27 19:16] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.42419\tvalid_1's multi_logloss: 0.778101\n",
      "[200]\ttraining's multi_logloss: 0.194384\tvalid_1's multi_logloss: 0.647383\n",
      "[300]\ttraining's multi_logloss: 0.0974057\tvalid_1's multi_logloss: 0.599505\n",
      "[400]\ttraining's multi_logloss: 0.0526623\tvalid_1's multi_logloss: 0.589923\n",
      "[500]\ttraining's multi_logloss: 0.0303733\tvalid_1's multi_logloss: 0.591528\n",
      "Early stopping, best iteration is:\n",
      "[425]\ttraining's multi_logloss: 0.0454814\tvalid_1's multi_logloss: 0.586493\n",
      "[2018-07-27 19:16] 10 F1: 0.8029565020016053\n",
      "Fold 11/5*5\n",
      "[2018-07-27 19:17] Encoders...\n",
      "(2388, 158)\n",
      "TE\n",
      "X_train: (2388, 6), X_valid: (632, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2388, 6), X_valid_enc: (632, 6), X_train_enc: (2388, 6)\n",
      "HE0\n",
      "X_train: (2388, 158), X_valid: (632, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2388, 4), X_valid_enc: (632, 4), X_train_enc: (2388, 4)\n",
      "HE1\n",
      "X_train: (2388, 6), X_valid: (632, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2388, 4), X_valid_enc: (632, 4), X_train_enc: (2388, 4)\n",
      "(2388, 172)\n",
      "[2018-07-27 19:17] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.424594\tvalid_1's multi_logloss: 0.819133\n",
      "[200]\ttraining's multi_logloss: 0.197666\tvalid_1's multi_logloss: 0.741142\n",
      "[300]\ttraining's multi_logloss: 0.0988634\tvalid_1's multi_logloss: 0.721468\n",
      "Early stopping, best iteration is:\n",
      "[277]\ttraining's multi_logloss: 0.115628\tvalid_1's multi_logloss: 0.719072\n",
      "[2018-07-27 19:17] 11 F1: 0.755535815403704\n",
      "Fold 12/5*5\n",
      "[2018-07-27 19:17] Encoders...\n",
      "(2440, 158)\n",
      "TE\n",
      "X_train: (2440, 6), X_valid: (580, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2440, 6), X_valid_enc: (580, 6), X_train_enc: (2440, 6)\n",
      "HE0\n",
      "X_train: (2440, 158), X_valid: (580, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2440, 4), X_valid_enc: (580, 4), X_train_enc: (2440, 4)\n",
      "HE1\n",
      "X_train: (2440, 6), X_valid: (580, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2440, 4), X_valid_enc: (580, 4), X_train_enc: (2440, 4)\n",
      "(2440, 172)\n",
      "[2018-07-27 19:18] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.426648\tvalid_1's multi_logloss: 0.741044\n",
      "[200]\ttraining's multi_logloss: 0.196105\tvalid_1's multi_logloss: 0.624778\n",
      "[300]\ttraining's multi_logloss: 0.0988552\tvalid_1's multi_logloss: 0.585391\n",
      "[400]\ttraining's multi_logloss: 0.0529596\tvalid_1's multi_logloss: 0.577911\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttraining's multi_logloss: 0.0560838\tvalid_1's multi_logloss: 0.576829\n",
      "[2018-07-27 19:18] 12 F1: 0.8026317343298781\n",
      "Fold 13/5*5\n",
      "[2018-07-27 19:18] Encoders...\n",
      "(2436, 158)\n",
      "TE\n",
      "X_train: (2436, 6), X_valid: (584, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2436, 6), X_valid_enc: (584, 6), X_train_enc: (2436, 6)\n",
      "HE0\n",
      "X_train: (2436, 158), X_valid: (584, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2436, 4), X_valid_enc: (584, 4), X_train_enc: (2436, 4)\n",
      "HE1\n",
      "X_train: (2436, 6), X_valid: (584, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2436, 4), X_valid_enc: (584, 4), X_train_enc: (2436, 4)\n",
      "(2436, 172)\n",
      "[2018-07-27 19:19] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.423842\tvalid_1's multi_logloss: 0.718355\n",
      "[200]\ttraining's multi_logloss: 0.193806\tvalid_1's multi_logloss: 0.605029\n",
      "[300]\ttraining's multi_logloss: 0.0976799\tvalid_1's multi_logloss: 0.560632\n",
      "[400]\ttraining's multi_logloss: 0.0527695\tvalid_1's multi_logloss: 0.549428\n",
      "[500]\ttraining's multi_logloss: 0.0305851\tvalid_1's multi_logloss: 0.547064\n",
      "Early stopping, best iteration is:\n",
      "[434]\ttraining's multi_logloss: 0.0432833\tvalid_1's multi_logloss: 0.545991\n",
      "[2018-07-27 19:19] 13 F1: 0.8059600659301558\n",
      "Fold 14/5*5\n",
      "[2018-07-27 19:19] Encoders...\n",
      "(2460, 158)\n",
      "TE\n",
      "X_train: (2460, 6), X_valid: (560, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2460, 6), X_valid_enc: (560, 6), X_train_enc: (2460, 6)\n",
      "HE0\n",
      "X_train: (2460, 158), X_valid: (560, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2460, 4), X_valid_enc: (560, 4), X_train_enc: (2460, 4)\n",
      "HE1\n",
      "X_train: (2460, 6), X_valid: (560, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2460, 4), X_valid_enc: (560, 4), X_train_enc: (2460, 4)\n",
      "(2460, 172)\n",
      "[2018-07-27 19:20] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.425354\tvalid_1's multi_logloss: 0.747339\n",
      "[200]\ttraining's multi_logloss: 0.195405\tvalid_1's multi_logloss: 0.624621\n",
      "[300]\ttraining's multi_logloss: 0.0984221\tvalid_1's multi_logloss: 0.584289\n",
      "[400]\ttraining's multi_logloss: 0.0540564\tvalid_1's multi_logloss: 0.5686\n",
      "[500]\ttraining's multi_logloss: 0.0315418\tvalid_1's multi_logloss: 0.573284\n",
      "Early stopping, best iteration is:\n",
      "[400]\ttraining's multi_logloss: 0.0540564\tvalid_1's multi_logloss: 0.5686\n",
      "[2018-07-27 19:20] 14 F1: 0.799823211922794\n",
      "Fold 15/5*5\n",
      "[2018-07-27 19:20] Encoders...\n",
      "(2356, 158)\n",
      "TE\n",
      "X_train: (2356, 6), X_valid: (664, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2356, 6), X_valid_enc: (664, 6), X_train_enc: (2356, 6)\n",
      "HE0\n",
      "X_train: (2356, 158), X_valid: (664, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2356, 4), X_valid_enc: (664, 4), X_train_enc: (2356, 4)\n",
      "HE1\n",
      "X_train: (2356, 6), X_valid: (664, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2356, 4), X_valid_enc: (664, 4), X_train_enc: (2356, 4)\n",
      "(2356, 172)\n",
      "[2018-07-27 19:21] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.422501\tvalid_1's multi_logloss: 0.808376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's multi_logloss: 0.191681\tvalid_1's multi_logloss: 0.706553\n",
      "[300]\ttraining's multi_logloss: 0.0944758\tvalid_1's multi_logloss: 0.680805\n",
      "[400]\ttraining's multi_logloss: 0.0505164\tvalid_1's multi_logloss: 0.680826\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's multi_logloss: 0.0754093\tvalid_1's multi_logloss: 0.676144\n",
      "[2018-07-27 19:21] 15 F1: 0.7704090408612336\n",
      "Fold 16/5*5\n",
      "[2018-07-27 19:21] Encoders...\n",
      "(2412, 158)\n",
      "TE\n",
      "X_train: (2412, 6), X_valid: (608, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2412, 6), X_valid_enc: (608, 6), X_train_enc: (2412, 6)\n",
      "HE0\n",
      "X_train: (2412, 158), X_valid: (608, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2412, 4), X_valid_enc: (608, 4), X_train_enc: (2412, 4)\n",
      "HE1\n",
      "X_train: (2412, 6), X_valid: (608, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2412, 4), X_valid_enc: (608, 4), X_train_enc: (2412, 4)\n",
      "(2412, 172)\n",
      "[2018-07-27 19:22] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.426823\tvalid_1's multi_logloss: 0.722538\n",
      "[200]\ttraining's multi_logloss: 0.195239\tvalid_1's multi_logloss: 0.603102\n",
      "[300]\ttraining's multi_logloss: 0.0994436\tvalid_1's multi_logloss: 0.565343\n",
      "[400]\ttraining's multi_logloss: 0.0538895\tvalid_1's multi_logloss: 0.549078\n",
      "[500]\ttraining's multi_logloss: 0.0314483\tvalid_1's multi_logloss: 0.543773\n",
      "Early stopping, best iteration is:\n",
      "[494]\ttraining's multi_logloss: 0.0324013\tvalid_1's multi_logloss: 0.543327\n",
      "[2018-07-27 19:22] 16 F1: 0.8112713213764886\n",
      "Fold 17/5*5\n",
      "[2018-07-27 19:22] Encoders...\n",
      "(2468, 158)\n",
      "TE\n",
      "X_train: (2468, 6), X_valid: (552, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2468, 6), X_valid_enc: (552, 6), X_train_enc: (2468, 6)\n",
      "HE0\n",
      "X_train: (2468, 158), X_valid: (552, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2468, 4), X_valid_enc: (552, 4), X_train_enc: (2468, 4)\n",
      "HE1\n",
      "X_train: (2468, 6), X_valid: (552, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2468, 4), X_valid_enc: (552, 4), X_train_enc: (2468, 4)\n",
      "(2468, 172)\n",
      "[2018-07-27 19:23] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.429058\tvalid_1's multi_logloss: 0.750161\n",
      "[200]\ttraining's multi_logloss: 0.200531\tvalid_1's multi_logloss: 0.627228\n",
      "[300]\ttraining's multi_logloss: 0.102388\tvalid_1's multi_logloss: 0.581166\n",
      "[400]\ttraining's multi_logloss: 0.0555648\tvalid_1's multi_logloss: 0.566255\n",
      "[500]\ttraining's multi_logloss: 0.0325917\tvalid_1's multi_logloss: 0.567386\n",
      "Early stopping, best iteration is:\n",
      "[431]\ttraining's multi_logloss: 0.0467336\tvalid_1's multi_logloss: 0.562885\n",
      "[2018-07-27 19:23] 17 F1: 0.8121805242776311\n",
      "Fold 18/5*5\n",
      "[2018-07-27 19:23] Encoders...\n",
      "(2416, 158)\n",
      "TE\n",
      "X_train: (2416, 6), X_valid: (604, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2416, 6), X_valid_enc: (604, 6), X_train_enc: (2416, 6)\n",
      "HE0\n",
      "X_train: (2416, 158), X_valid: (604, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2416, 4), X_valid_enc: (604, 4), X_train_enc: (2416, 4)\n",
      "HE1\n",
      "X_train: (2416, 6), X_valid: (604, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2416, 4), X_valid_enc: (604, 4), X_train_enc: (2416, 4)\n",
      "(2416, 172)\n",
      "[2018-07-27 19:24] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.423539\tvalid_1's multi_logloss: 0.726511\n",
      "[200]\ttraining's multi_logloss: 0.195498\tvalid_1's multi_logloss: 0.598098\n",
      "[300]\ttraining's multi_logloss: 0.0989482\tvalid_1's multi_logloss: 0.552153\n",
      "[400]\ttraining's multi_logloss: 0.0537366\tvalid_1's multi_logloss: 0.533809\n",
      "[500]\ttraining's multi_logloss: 0.0313637\tvalid_1's multi_logloss: 0.527762\n",
      "Early stopping, best iteration is:\n",
      "[486]\ttraining's multi_logloss: 0.0336184\tvalid_1's multi_logloss: 0.527615\n",
      "[2018-07-27 19:24] 18 F1: 0.8310232520202373\n",
      "Fold 19/5*5\n",
      "[2018-07-27 19:24] Encoders...\n",
      "(2400, 158)\n",
      "TE\n",
      "X_train: (2400, 6), X_valid: (620, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2400, 6), X_valid_enc: (620, 6), X_train_enc: (2400, 6)\n",
      "HE0\n",
      "X_train: (2400, 158), X_valid: (620, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2400, 4), X_valid_enc: (620, 4), X_train_enc: (2400, 4)\n",
      "HE1\n",
      "X_train: (2400, 6), X_valid: (620, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2400, 4), X_valid_enc: (620, 4), X_train_enc: (2400, 4)\n",
      "(2400, 172)\n",
      "[2018-07-27 19:25] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.423331\tvalid_1's multi_logloss: 0.725974\n",
      "[200]\ttraining's multi_logloss: 0.194627\tvalid_1's multi_logloss: 0.611177\n",
      "[300]\ttraining's multi_logloss: 0.0978215\tvalid_1's multi_logloss: 0.56683\n",
      "[400]\ttraining's multi_logloss: 0.052958\tvalid_1's multi_logloss: 0.55039\n",
      "[500]\ttraining's multi_logloss: 0.0309113\tvalid_1's multi_logloss: 0.546213\n",
      "[600]\ttraining's multi_logloss: 0.0195576\tvalid_1's multi_logloss: 0.55143\n",
      "Early stopping, best iteration is:\n",
      "[516]\ttraining's multi_logloss: 0.0285056\tvalid_1's multi_logloss: 0.545324\n",
      "[2018-07-27 19:25] 19 F1: 0.8219800688429935\n",
      "Fold 20/5*5\n",
      "[2018-07-27 19:25] Encoders...\n",
      "(2384, 158)\n",
      "TE\n",
      "X_train: (2384, 6), X_valid: (636, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2384, 6), X_valid_enc: (636, 6), X_train_enc: (2384, 6)\n",
      "HE0\n",
      "X_train: (2384, 158), X_valid: (636, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2384, 4), X_valid_enc: (636, 4), X_train_enc: (2384, 4)\n",
      "HE1\n",
      "X_train: (2384, 6), X_valid: (636, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2384, 4), X_valid_enc: (636, 4), X_train_enc: (2384, 4)\n",
      "(2384, 172)\n",
      "[2018-07-27 19:26] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.429592\tvalid_1's multi_logloss: 0.749443\n",
      "[200]\ttraining's multi_logloss: 0.199257\tvalid_1's multi_logloss: 0.627452\n",
      "[300]\ttraining's multi_logloss: 0.100386\tvalid_1's multi_logloss: 0.585288\n",
      "[400]\ttraining's multi_logloss: 0.0543393\tvalid_1's multi_logloss: 0.566339\n",
      "[500]\ttraining's multi_logloss: 0.0316532\tvalid_1's multi_logloss: 0.563263\n",
      "Early stopping, best iteration is:\n",
      "[472]\ttraining's multi_logloss: 0.0365598\tvalid_1's multi_logloss: 0.561492\n",
      "[2018-07-27 19:26] 20 F1: 0.8107403315526225\n",
      "Fold 21/5*5\n",
      "[2018-07-27 19:26] Encoders...\n",
      "(2448, 158)\n",
      "TE\n",
      "X_train: (2448, 6), X_valid: (572, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2448, 6), X_valid_enc: (572, 6), X_train_enc: (2448, 6)\n",
      "HE0\n",
      "X_train: (2448, 158), X_valid: (572, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2448, 4), X_valid_enc: (572, 4), X_train_enc: (2448, 4)\n",
      "HE1\n",
      "X_train: (2448, 6), X_valid: (572, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2448, 4), X_valid_enc: (572, 4), X_train_enc: (2448, 4)\n",
      "(2448, 172)\n",
      "[2018-07-27 19:27] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.429336\tvalid_1's multi_logloss: 0.747298\n",
      "[200]\ttraining's multi_logloss: 0.198802\tvalid_1's multi_logloss: 0.61905\n",
      "[300]\ttraining's multi_logloss: 0.100993\tvalid_1's multi_logloss: 0.561443\n",
      "[400]\ttraining's multi_logloss: 0.0544204\tvalid_1's multi_logloss: 0.544898\n",
      "[500]\ttraining's multi_logloss: 0.0319619\tvalid_1's multi_logloss: 0.54316\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's multi_logloss: 0.0383673\tvalid_1's multi_logloss: 0.541101\n",
      "[2018-07-27 19:27] 21 F1: 0.824914505097432\n",
      "Fold 22/5*5\n",
      "[2018-07-27 19:27] Encoders...\n",
      "(2420, 158)\n",
      "TE\n",
      "X_train: (2420, 6), X_valid: (600, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2420, 6), X_valid_enc: (600, 6), X_train_enc: (2420, 6)\n",
      "HE0\n",
      "X_train: (2420, 158), X_valid: (600, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2420, 4), X_valid_enc: (600, 4), X_train_enc: (2420, 4)\n",
      "HE1\n",
      "X_train: (2420, 6), X_valid: (600, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2420, 4), X_valid_enc: (600, 4), X_train_enc: (2420, 4)\n",
      "(2420, 172)\n",
      "[2018-07-27 19:28] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.442298\tvalid_1's multi_logloss: 0.735704\n",
      "[200]\ttraining's multi_logloss: 0.208189\tvalid_1's multi_logloss: 0.590219\n",
      "[300]\ttraining's multi_logloss: 0.106657\tvalid_1's multi_logloss: 0.523995\n",
      "[400]\ttraining's multi_logloss: 0.0584173\tvalid_1's multi_logloss: 0.497512\n",
      "[500]\ttraining's multi_logloss: 0.0341677\tvalid_1's multi_logloss: 0.486605\n",
      "[600]\ttraining's multi_logloss: 0.0214557\tvalid_1's multi_logloss: 0.486078\n",
      "[700]\ttraining's multi_logloss: 0.0145156\tvalid_1's multi_logloss: 0.490003\n",
      "Early stopping, best iteration is:\n",
      "[654]\ttraining's multi_logloss: 0.0172339\tvalid_1's multi_logloss: 0.485477\n",
      "[2018-07-27 19:28] 22 F1: 0.8256324714076915\n",
      "Fold 23/5*5\n",
      "[2018-07-27 19:28] Encoders...\n",
      "(2412, 158)\n",
      "TE\n",
      "X_train: (2412, 6), X_valid: (608, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2412, 6), X_valid_enc: (608, 6), X_train_enc: (2412, 6)\n",
      "HE0\n",
      "X_train: (2412, 158), X_valid: (608, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2412, 4), X_valid_enc: (608, 4), X_train_enc: (2412, 4)\n",
      "HE1\n",
      "X_train: (2412, 6), X_valid: (608, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2412, 4), X_valid_enc: (608, 4), X_train_enc: (2412, 4)\n",
      "(2412, 172)\n",
      "[2018-07-27 19:29] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.436012\tvalid_1's multi_logloss: 0.772248\n",
      "[200]\ttraining's multi_logloss: 0.200401\tvalid_1's multi_logloss: 0.66531\n",
      "[300]\ttraining's multi_logloss: 0.101409\tvalid_1's multi_logloss: 0.625489\n",
      "[400]\ttraining's multi_logloss: 0.0547713\tvalid_1's multi_logloss: 0.615025\n",
      "[500]\ttraining's multi_logloss: 0.0318961\tvalid_1's multi_logloss: 0.622858\n",
      "Early stopping, best iteration is:\n",
      "[411]\ttraining's multi_logloss: 0.0513247\tvalid_1's multi_logloss: 0.614767\n",
      "[2018-07-27 19:29] 23 F1: 0.787035494274074\n",
      "Fold 24/5*5\n",
      "[2018-07-27 19:29] Encoders...\n",
      "(2368, 158)\n",
      "TE\n",
      "X_train: (2368, 6), X_valid: (652, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2368, 6), X_valid_enc: (652, 6), X_train_enc: (2368, 6)\n",
      "HE0\n",
      "X_train: (2368, 158), X_valid: (652, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2368, 4), X_valid_enc: (652, 4), X_train_enc: (2368, 4)\n",
      "HE1\n",
      "X_train: (2368, 6), X_valid: (652, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2368, 4), X_valid_enc: (652, 4), X_train_enc: (2368, 4)\n",
      "(2368, 172)\n",
      "[2018-07-27 19:30] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.423358\tvalid_1's multi_logloss: 0.764925\n",
      "[200]\ttraining's multi_logloss: 0.194008\tvalid_1's multi_logloss: 0.637865\n",
      "[300]\ttraining's multi_logloss: 0.0962555\tvalid_1's multi_logloss: 0.598374\n",
      "[400]\ttraining's multi_logloss: 0.0518819\tvalid_1's multi_logloss: 0.584428\n",
      "[500]\ttraining's multi_logloss: 0.0300962\tvalid_1's multi_logloss: 0.587439\n",
      "Early stopping, best iteration is:\n",
      "[423]\ttraining's multi_logloss: 0.0453785\tvalid_1's multi_logloss: 0.580466\n",
      "[2018-07-27 19:30] 24 F1: 0.8079450015593703\n",
      "Fold 25/5*5\n",
      "[2018-07-27 19:30] Encoders...\n",
      "(2432, 158)\n",
      "TE\n",
      "X_train: (2432, 6), X_valid: (588, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2432, 6), X_valid_enc: (588, 6), X_train_enc: (2432, 6)\n",
      "HE0\n",
      "X_train: (2432, 158), X_valid: (588, 158), X_test: (23856, 158)\n",
      "X_train_enc: (2432, 4), X_valid_enc: (588, 4), X_train_enc: (2432, 4)\n",
      "HE1\n",
      "X_train: (2432, 6), X_valid: (588, 6), X_test: (23856, 6)\n",
      "X_train_enc: (2432, 4), X_valid_enc: (588, 4), X_train_enc: (2432, 4)\n",
      "(2432, 172)\n",
      "[2018-07-27 19:31] Done.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's multi_logloss: 0.4316\tvalid_1's multi_logloss: 0.698148\n",
      "[200]\ttraining's multi_logloss: 0.200194\tvalid_1's multi_logloss: 0.566189\n",
      "[300]\ttraining's multi_logloss: 0.101343\tvalid_1's multi_logloss: 0.515758\n",
      "[400]\ttraining's multi_logloss: 0.0555252\tvalid_1's multi_logloss: 0.500551\n",
      "[500]\ttraining's multi_logloss: 0.032521\tvalid_1's multi_logloss: 0.499637\n",
      "Early stopping, best iteration is:\n",
      "[436]\ttraining's multi_logloss: 0.0454114\tvalid_1's multi_logloss: 0.496918\n",
      "[2018-07-27 19:31] 25 F1: 0.8447207380324151\n"
     ]
    }
   ],
   "source": [
    "for train_index, valid_index in kf.split(X, y):\n",
    "    print('Fold {}/{}*{}'.format(cnt + 1, n_splits, n_repeats))\n",
    "    params = lgb_params.copy() \n",
    "\n",
    "    sampler = RandomUnderSampler(random_state=0)\n",
    "    X_train_index, y_train = sampler.fit_sample(train_index.reshape(-1, 1), y_le[train_index])\n",
    "    X_valid_index, y_valid = sampler.fit_sample(valid_index.reshape(-1, 1), y_le[valid_index])\n",
    "\n",
    "    # print(train_index, X_train_index)\n",
    "    X_train = X.loc[X_train_index.ravel()].copy()\n",
    "    X_valid = X.loc[X_valid_index.ravel()].copy()\n",
    "    X_test_te = X_test.copy()\n",
    "\n",
    "    dprint('Encoders...')  \n",
    "    print(X_train.shape) \n",
    "    \n",
    "    def encode(encoder, cols, X_train, X_valid, X_test, y_train, suffix='enc'):\n",
    "        print('X_train: {}, X_valid: {}, X_test: {}'.format(\n",
    "            X_train.shape, \n",
    "            X_valid.shape, \n",
    "            X_test.shape))\n",
    "        encoder.fit(X_train, y_train)\n",
    "        X_train_enc = encoder.transform(X_train.copy())\n",
    "        X_valid_enc = encoder.transform(X_valid.copy())\n",
    "        X_test_enc = encoder.transform(X_test.copy())\n",
    "\n",
    "        X_train_enc.columns = [c + '_' + suffix for c in X_train_enc.columns]\n",
    "        X_valid_enc.columns = [c + '_' + suffix for c in X_valid_enc.columns]\n",
    "        X_test_enc.columns = [c + '_' + suffix for c in X_test_enc.columns]\n",
    "\n",
    "        print('X_train_enc: {}, X_valid_enc: {}, X_train_enc: {}'.format(\n",
    "            X_train_enc.shape, \n",
    "            X_valid_enc.shape, \n",
    "            X_train_enc.shape))\n",
    "\n",
    "        return X_train_enc, X_valid_enc, X_test_enc\n",
    "\n",
    "    print('TE')\n",
    "    encoder = ce.TargetEncoder(cols=enc_cols)\n",
    "    X_train_enc0, X_valid_enc0, X_test_enc0 = encode(\n",
    "        encoder, \n",
    "        enc_cols, \n",
    "        X_train[enc_cols], \n",
    "        X_valid[enc_cols], \n",
    "        X_test_te[enc_cols], \n",
    "        y_train,\n",
    "        suffix='te')\n",
    "\n",
    "    X_train = pd.concat([X_train, X_train_enc0], axis=1)\n",
    "    X_valid = pd.concat([X_valid, X_valid_enc0], axis=1)\n",
    "    X_test_te = pd.concat([X_test_te, X_test_enc0], axis=1)\n",
    "\n",
    "    print('HE0')\n",
    "    encoder = ce.HashingEncoder(cols=feature_names_initial, n_components=4)\n",
    "    X_train_enc1, X_valid_enc1, X_test_enc1 = encode(\n",
    "        encoder, \n",
    "        feature_names_initial, \n",
    "        X_train[feature_names_initial], \n",
    "        X_valid[feature_names_initial], \n",
    "        X_test_te[feature_names_initial], \n",
    "        y_train,\n",
    "        suffix='he0')\n",
    "\n",
    "    X_train = pd.concat([X_train, X_train_enc1], axis=1)\n",
    "    X_valid = pd.concat([X_valid, X_valid_enc1], axis=1)\n",
    "    X_test_te = pd.concat([X_test_te, X_test_enc1], axis=1)\n",
    "\n",
    "    print('HE1')\n",
    "    encoder = ce.HashingEncoder(cols=enc_cols, n_components=4)\n",
    "    X_train_enc2, X_valid_enc2, X_test_enc2 = encode(\n",
    "        encoder, \n",
    "        enc_cols, \n",
    "        X_train[enc_cols], \n",
    "        X_valid[enc_cols], \n",
    "        X_test_te[enc_cols], \n",
    "        y_train,\n",
    "        suffix='he1')\n",
    "\n",
    "    X_train = pd.concat([X_train, X_train_enc2], axis=1)\n",
    "    X_valid = pd.concat([X_valid, X_valid_enc2], axis=1)\n",
    "    X_test_te = pd.concat([X_test_te, X_test_enc2], axis=1)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    feature_names = list(X_train.columns)\n",
    "    dprint(\"Done.\")\n",
    "\n",
    "    X_train = X_train.values\n",
    "    X_valid = X_valid.values\n",
    "    X_test_te = X_test_te.values\n",
    "\n",
    "    lgb_train = lgb.Dataset(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        feature_name=feature_names,\n",
    "        )\n",
    "    lgb_train.raw_data = None\n",
    "\n",
    "    lgb_valid = lgb.Dataset(\n",
    "        X_valid, \n",
    "        y_valid,\n",
    "        feature_name=feature_names,\n",
    "        )\n",
    "    lgb_valid.raw_data = None\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb_train,\n",
    "        num_boost_round=99999,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        early_stopping_rounds=100, \n",
    "        verbose_eval=100, \n",
    "    )\n",
    "\n",
    "    if cnt == 0:\n",
    "        importance = model.feature_importance()\n",
    "        model_fnames = model.feature_name()\n",
    "        tuples = sorted(zip(model_fnames, importance), key=lambda x: x[1])[::-1]\n",
    "        tuples = [x for x in tuples if x[1] > 0]\n",
    "        print('Important features:')\n",
    "        for i in range(20):\n",
    "            if i < len(tuples):\n",
    "                print(i, tuples[i])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        del importance, model_fnames, tuples\n",
    "\n",
    "    p = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "\n",
    "    err = f1_score(y_valid, np.argmax(p, axis=1), average='macro')\n",
    "\n",
    "    dprint('{} F1: {}'.format(cnt + 1, err))\n",
    "\n",
    "    p = model.predict(X_test_te, num_iteration=model.best_iteration)\n",
    "    if len(p_buf) == 0:\n",
    "        p_buf = np.array(p, dtype=np.float16)\n",
    "    else:\n",
    "        p_buf += np.array(p, dtype=np.float16)\n",
    "    err_buf.append(err)\n",
    "\n",
    "    cnt += 1\n",
    "    # if cnt > 0: # Comment this to run several folds\n",
    "    #     break\n",
    "\n",
    "    del model, lgb_train, lgb_valid, p\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 = 0.811012 +/- 0.022016\n"
     ]
    }
   ],
   "source": [
    "err_mean = np.mean(err_buf)\n",
    "err_std = np.std(err_buf)\n",
    "print('F1 = {:.6f} +/- {:.6f}'.format(err_mean, err_std))\n",
    "\n",
    "preds = p_buf/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probas\n",
    "subm = pd.DataFrame()\n",
    "subm[id_name] = id_test\n",
    "for i in range(preds.shape[1]):\n",
    "    subm[i2c[i]] = preds[:, i]\n",
    "subm.to_csv('submission_{:.6f}_probas.csv'.format(err_mean), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "subm = pd.DataFrame()\n",
    "subm[id_name] = id_test\n",
    "subm[target_name] = [i2c[np.argmax(p)] for p in preds]\n",
    "subm[target_name] = subm[target_name].astype(int)\n",
    "subm.to_csv('submission_{:.6f}.csv'.format(err_mean), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
