{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poverty Level Prediction Light Gradient Boosting with CV and Seed Diversification\n",
    "# By Nick Brooks, July 2018\n",
    "# https://www.kaggle.com/nicapotato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "notebookstart= time.time()\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import random\n",
    "from contextlib import contextmanager\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model\n",
    "import lightgbm as lgb\n",
    "random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\\n\".format(title, time.time() - t0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(Debug = False):\n",
    "    print(\"Load Data\")\n",
    "    nrows = None\n",
    "    if Debug is True: nrows= 500\n",
    "    train = pd.read_csv(\"../../data/Kaggle_IADB_Competition/train.csv\", index_col = \"Id\", nrows=nrows)\n",
    "    traindex = train.index\n",
    "    test_df = pd.read_csv(\"../../data/Kaggle_IADB_Competition/test.csv\", index_col = \"Id\", nrows=nrows)\n",
    "    testdex = test_df.index\n",
    "    y = train.Target.copy()\n",
    "    y = y - 1\n",
    "    train.drop(\"Target\", axis=1, inplace=True)\n",
    "    \n",
    "    return train, traindex, test_df, testdex, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test_df, traindex, testdex):\n",
    "    print(\"Preprocessing Stage:\")\n",
    "    df = pd.concat([train,test_df],axis=0)\n",
    "    dfdex = df.index\n",
    "    # Label Encode\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    for col in train.loc[:,train.dtypes == \"object\"].columns:\n",
    "        df[col] = lbl.fit_transform(df[col].astype(str))\n",
    "        \n",
    "    # Create Room Features- https://www.kaggle.com/opanichev/lgb-as-always\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms']\n",
    "    \n",
    "    # Average by household ID\n",
    "    householdagg = df.groupby(\"idhogar\").agg({k:[\"sum\",\"mean\",\"max\",\"min\",\"std\"] for k in train.columns if k not in \"idhogar\"})\n",
    "    householdagg.columns = pd.Index([\"household_agg_\" + e[0] +\"_\"+ e[1] for e in householdagg.columns.tolist()])\n",
    "    df = pd.merge(df,householdagg, left_on=\"idhogar\", right_on=\"idhogar\", how= \"left\")\n",
    "    df.index = dfdex\n",
    "    \n",
    "    # Split\n",
    "    train = df.loc[traindex,:]\n",
    "    test_df = df.loc[testdex,:]\n",
    "    \n",
    "    return train, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_cv(y, lgtrain):\n",
    "    print(\"Light Gradient Boosting Classifier: \")\n",
    "    lgbm_params =  {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': y.nunique(),\n",
    "        'metric': ['multi_logloss'],\n",
    "        \"learning_rate\": 0.05,\n",
    "         \"num_leaves\": 80,\n",
    "         \"max_depth\": 6,\n",
    "         \"feature_fraction\": 0.70,\n",
    "         \"bagging_fraction\": 0.75,\n",
    "         \"reg_alpha\": 0.15,\n",
    "         \"reg_lambda\": 0.15,\n",
    "          \"min_child_weight\": 0\n",
    "                    }\n",
    "                    \n",
    "    modelstart= time.time()\n",
    "    # Find Optimal Parameters / Boosting Rounds\n",
    "    lgb_cv = lgb.cv(\n",
    "        params = lgbm_params,\n",
    "        train_set = lgtrain,\n",
    "        num_boost_round=2000,\n",
    "        stratified=True,\n",
    "        nfold = 5,\n",
    "        verbose_eval=100,\n",
    "        seed = 23,\n",
    "        early_stopping_rounds=75)\n",
    "\n",
    "    loss = lgbm_params[\"metric\"][0]\n",
    "    optimal_rounds = np.argmin(lgb_cv[str(loss) + '-mean'])\n",
    "    best_cv_score = min(lgb_cv[str(loss) + '-mean'])\n",
    "\n",
    "    print(\"\\nOptimal Round: {}\\nOptimal Score: {} + {}\".format(\n",
    "        optimal_rounds,best_cv_score,lgb_cv[str(loss) + '-stdv'][optimal_rounds]))\n",
    "\n",
    "    return lgbm_params, optimal_rounds, best_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_seed_diversification(y, lgtrain, train, test_df, lgbm_params, optimal_rounds, best_cv_score):\n",
    "    print(\"Seed Diversification Stage:\")\n",
    "    allmodelstart= time.time()\n",
    "    # Run Model with different Seeds\n",
    "    multi_seed_pred = dict()\n",
    "    all_feature_importance_df  = pd.DataFrame()\n",
    "\n",
    "    # To submit each seed model seperately aswell\n",
    "    def seed_submit(test_df, model,seed):\n",
    "        # Output position with highest probability\n",
    "        class_prediction = (pd.DataFrame(model.predict(test_df)).idxmax(axis=1) + 1).rename('Id')\n",
    "        class_prediction.index = test_df.index\n",
    "\n",
    "        # Submit\n",
    "        class_prediction.to_csv('seed{}_sub_ep{}_sc{}.csv'.format(seed,optimal_rounds,round(best_cv_score,5))\n",
    "                    ,index = True, header=True)\n",
    "\n",
    "    all_seeds = [5,8,10,12]\n",
    "    for seeds_x in all_seeds:\n",
    "        modelstart= time.time()\n",
    "        print(\"Seed: \", seeds_x,)\n",
    "        # Go Go Go\n",
    "        lgbm_params[\"seed\"] = seeds_x\n",
    "        lgb_final = lgb.train(\n",
    "            lgbm_params,\n",
    "            lgtrain,\n",
    "            num_boost_round = optimal_rounds + 1,\n",
    "            verbose_eval=200)\n",
    "\n",
    "        # Feature Importance\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = train.columns\n",
    "        fold_importance_df[\"importance\"] = lgb_final.feature_importance()\n",
    "        all_feature_importance_df = pd.concat([all_feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        multi_seed_pred[seeds_x] =  pd.DataFrame(lgb_final.predict(test_df))\n",
    "        # Submit Model Individually\n",
    "        seed_submit(test_df, model= lgb_final, seed= seeds_x)\n",
    "        print(\"Model Runtime: %0.2f Minutes\"%((time.time() - modelstart)/60))\n",
    "        del lgb_final\n",
    "\n",
    "    cols = all_feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "        by=\"importance\", ascending=False)[:50].index\n",
    "    best_features = all_feature_importance_df.loc[all_feature_importance_df.feature.isin(cols)]\n",
    "    plt.figure(figsize=(8,10))\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", \n",
    "                data=best_features.sort_values(by=\"importance\", ascending=False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('lgb_finalm_importances.png')\n",
    "    print(\"All Model Runtime: %0.2f Minutes\"%((time.time() - allmodelstart)/60))\n",
    "\n",
    "    # Collapse Seed DataFrames\n",
    "    panel = pd.Panel(multi_seed_pred)\n",
    "    print(\"Seed Effect Breakdown: Classwise Statistics\")\n",
    "    for i,(std,mean) in enumerate(zip(panel.std(axis=0).mean(axis=0),panel.mean(axis=0).mean(axis=0))):\n",
    "        print(\"Class {}:\".format(i+1))\n",
    "        print(\"Mean {0:.3f} (+/-) {1:.5f}\\n\".format(mean,std))\n",
    "    \n",
    "    return panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_ensemble(y, testdex, panel):\n",
    "    print(\"Seed Ensemble Stage\")\n",
    "    # Take Mean over Seed prediction\n",
    "    mean_prob = panel.mean(axis=0)\n",
    "    # Output position with highest probability\n",
    "    class_prediction = mean_prob.idxmax(axis=1) + 1\n",
    "    class_prediction.rename(\"Target\",inplace=True)\n",
    "    class_prediction.index = testdex\n",
    "    print(\"Prediction Class Distribution:\\n\", class_prediction.value_counts(normalize=True))\n",
    "    print(\"Dependent Variable Class Distribution:\\n\", y.value_counts(normalize=True))\n",
    "    return class_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute All\n",
    "def main(Debug = False):\n",
    "    with timer(\"Load Data\"):\n",
    "        train, traindex, test_df, testdex, y = get_data(Debug=Debug)\n",
    "    with timer(\"Pre-Process\"):\n",
    "        train, test_df = preprocess(train, test_df, traindex, testdex)\n",
    "    with timer(\"LGBM CV\"):\n",
    "        # LGBM Dataset\n",
    "        lgtrain = lgb.Dataset(train,y ,feature_name = \"auto\")\n",
    "        print(\"Starting LightGBM. Train shape: {}, Test shape: {}\".format(train.shape,test_df.shape))\n",
    "        lgbm_params, optimal_rounds, best_cv_score = lgbm_cv(y, lgtrain)\n",
    "    with timer(\"Seed Diversification\"):\n",
    "        panel = lgbm_seed_diversification(y, lgtrain, train, test_df, lgbm_params, optimal_rounds, best_cv_score)\n",
    "    with timer(\"Seed Ensemble\"):\n",
    "        class_prediction = seed_ensemble(y, testdex, panel)\n",
    "    with timer(\"Submit\"):\n",
    "        class_prediction.to_csv('seed_mean_sub_rounds_{}_score_{}.csv'.format(optimal_rounds,round(best_cv_score,5))\n",
    "                    ,index = True, header=True)\n",
    "        print(class_prediction.head())\n",
    "        print(\"Notebook Runtime: %0.2f Minutes\"%((time.time() - notebookstart)/60))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(Debug = False)\n",
    "\n",
    "# Don't Forget to check the LOG! Happy Kaggling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
